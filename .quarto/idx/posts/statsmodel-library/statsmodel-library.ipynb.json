{"title":"The statsmodel Python Library","markdown":{"yaml":{"title":"The statsmodel Python Library","date":"2025-02-01","description":"Comparing and contrasting the statsmodel library against standard R Language","categories":["Python","R"]},"headingText":"Python","containsRefs":false,"markdown":"\n\nWhen thinking about a data science project, one of the first decisions I find myself having to make is which language I want to do the project with. My first two choices are generally R or Python. Both languages have the capabilities to do high level data science work, but each has its pros and cons as well.\n\nPython is often one of the first languages a new programmer learns. Its syntax is intuitive and the language has become quite popular over recent years, in part because of the ([community of open source libraries](https://pypi.org/)) that are easy to import to a script. \n\nA drawback to Python, however, is that it does not come built in with data frame capabilities and requires a third-party library (Pandas being the most popular) to structure data in a way that is easier to work with. You can structure data in lists, arrays, and dictionaries, but it requires a fair amount of code to get the data structured in a way you can work with it. \n\nFor how intuitive most of the language's syntax is, visualizations are not the easiest to create either. Matplotlib is a popular library to create visualizations, but it is not as straightforward as some of the packages or built in capabilities available in R.\n\n# R\nR is a programming language that is built by data scientists for data scientists. The language is widely used in academia and can complete complex statistical tasks with relatively little code. R also has built in data frame handling capabilities. When working with a large data set, it is quite easy to bring the data set into your environment and begin working with it immediately. \n\nWhile the ([Comprehensive R Archive Network (CRAN)](https://cran.r-project.org/)) has some great libraries available, the roughly 19,000 packages available pale in comparaison to the over 300,000 that are available in Python. Even then, some packages are not maintained but still available and won't work properly if you are using many libraries. Further, the learning curve on R is much steeper than Python because the syntax often does not resemble simple human language in the way that Python does. \n\n# Personal Greviances\nConsider this section of the blog my personal Festivus celebration. To paraphrase Frank Constanza, the tradition of data science begins with an airing of grievances. This is my blog, I have a lot of problems with these languages, and now you're gonna hear about it.\n\nMy biggest complaint with Python is that there is often a ton of data preprocessing that needs to be done in order to get the data ready to build a model. And even then, trying to get the data into the actual model is an arduous task. I spend more time fighting with data types in R than I do in any other language as well. Why there is so much trouble casting a 3 from a character to an integer I will never understand. It's in my data set as an integer, why are you reading it as a character, R?\n\n# There Has To Be A Better Way\nEnter, the ([statsmodels](https://www.statsmodels.org/stable/index.html)) Python library. From the statsmodels website, this library \"supports specifying models using R-style formulas\". My understanding is that this should create a best of both worlds situations in that we can leverage the speed and third-party libraries of Python while also maintaining the simple statistical model creation found in R.\n\n# About statsmodels\nThe statsmodels package was originally written as the models module of the scipy.stats package. When the module was removed in the late 2000s, developer Jonathan Taylor improved the package and decided to release it on its own.\n\nstatsmodels has a host of statistical modeling capabilites available through the statsmodels.api, statsmodels.tsa.api, and statsmodels.formula.api, models. A full list is available ([here](https://www.statsmodels.org/stable/api.html)) with documentation to go along with each.\n\n# An Example\nTo try this pacage out, I want to use this library to see how much returning production influences a college football team's winning. With the rise of the transfer portal in college football, there is a new debate over whether a team should seek out the best talent in the portal, or recruit players out of high school and develop them in their system. A team's percentage of returning EPA (called PPA in our data API) will serve as our independent variable, and the team's winning percentage will be the dependent variable.\n\nEPA stands for Expected Points Added, and measures how many expected points are added or lost on a given play. For example, if a team has the ball on their own 20 yard line, they might be expected to get 2.5 point on that drive. But if they throw a 75 yard pass to take the ball down to the opponents 5 yard line, their expected points for the drive might rise to 6.5. The EPA for that play would be 4. I don't know the exact breakdown of expected points on every yard line, but I this example should demonstrate how EPA works. \n\nI'll be pulling the data from the folks at ([CollegeFootballData](collegefootballdata.com)). I highly recommend this site for using college football data. If you wish to use this library, however, you will need to ([sign up for a free API key](https://collegefootballdata.com/key)) and configure it according to their instructions.\n\nAs you can see, we have a data frame created now with our EPA data. A note on the API response: the response is given as a list of objects, rather than as a dictionary, which is why we need to parse things out before creating a full dataframe.\n\nThe next thing we'll need to do is get the winning percentages for each of these teams and combine that with our EPA data.\n\nAgain we have to do a little extra cleaning when getting our data set up. A team's win/loss data come in as an object (you can see an example in the conferece_games, home_games, and away_games columns, I just left those alone because I don't need that granular information) so we have to do a little work to get the information from that object into its own columns, and then calculate winning percentage. \n\nNow that we have our data set up as needed, let's get to work with modeling. I'd like to do a comparison between the more traditional way of doing linear regression, out of the sklearn.linear_model.LinearRegression class, and doing it this new way with the stats model library. First off, this is how I would set up the data for sklearn.\n\nNow, this is a fairly basic example so there is not a ton that we need with our data before feeding it into our model. Of course, as we create more complex models this would become a more complex task. I am also able to pull out the summary information from the model, but it requires importing other classes and we have to write out formatted strings so we know what we are looking at. \n\nLet's compare this now to the statsmodels library. \n\n# Thoughts on statsmodels\nNow that we have our two models made, I have a couple of initial thoughts before dissecting the output of the models.\n\nThe first is that statsmodels on its own really doesn't incorporate R syntax as much as I initially thought that it would. In fact, it seems that the entire premise of using R syntax for creating models is more related to the ([patsy dependency](https://github.com/pydata/patsy)), which is no longer in development, than the statsmodels library itself.\n\nThat being said, I do find this far easier than sklearn. With statsmodels, I don't need to worry about converting my data into numpy arrays before putting the data into the model. The thing that I find most useful, however, is the fact that there is a built in summary method. Rather than having to pull each summary value out individually and getting it into a formatted string so I know what I am looking at, I can just do `model.summary()` and I can get a full look at what the model produces. \n\nI find this to be far more convenient, and I certainly think I would use statsmodels if given a choice between that and sklearn.\n\n# Evaluating our model\nOur model suggests that returning production plays a very small role, but important role in predicting team success. Our R-Squared value says that only 5% of the variance in a team's winning percentage is explained by returning production, but that there is a statistically significant relationship between the two. So the relationship is there, but the affect on a team's success is pretty weak. I don't think that I would use returning production as a real predictor of team success given what I see in this model. The relationship may be statistically significant, but it does not appear as though it is practically significant. \n","srcMarkdownNoYaml":"\n\nWhen thinking about a data science project, one of the first decisions I find myself having to make is which language I want to do the project with. My first two choices are generally R or Python. Both languages have the capabilities to do high level data science work, but each has its pros and cons as well.\n\n## Python\nPython is often one of the first languages a new programmer learns. Its syntax is intuitive and the language has become quite popular over recent years, in part because of the ([community of open source libraries](https://pypi.org/)) that are easy to import to a script. \n\nA drawback to Python, however, is that it does not come built in with data frame capabilities and requires a third-party library (Pandas being the most popular) to structure data in a way that is easier to work with. You can structure data in lists, arrays, and dictionaries, but it requires a fair amount of code to get the data structured in a way you can work with it. \n\nFor how intuitive most of the language's syntax is, visualizations are not the easiest to create either. Matplotlib is a popular library to create visualizations, but it is not as straightforward as some of the packages or built in capabilities available in R.\n\n# R\nR is a programming language that is built by data scientists for data scientists. The language is widely used in academia and can complete complex statistical tasks with relatively little code. R also has built in data frame handling capabilities. When working with a large data set, it is quite easy to bring the data set into your environment and begin working with it immediately. \n\nWhile the ([Comprehensive R Archive Network (CRAN)](https://cran.r-project.org/)) has some great libraries available, the roughly 19,000 packages available pale in comparaison to the over 300,000 that are available in Python. Even then, some packages are not maintained but still available and won't work properly if you are using many libraries. Further, the learning curve on R is much steeper than Python because the syntax often does not resemble simple human language in the way that Python does. \n\n# Personal Greviances\nConsider this section of the blog my personal Festivus celebration. To paraphrase Frank Constanza, the tradition of data science begins with an airing of grievances. This is my blog, I have a lot of problems with these languages, and now you're gonna hear about it.\n\nMy biggest complaint with Python is that there is often a ton of data preprocessing that needs to be done in order to get the data ready to build a model. And even then, trying to get the data into the actual model is an arduous task. I spend more time fighting with data types in R than I do in any other language as well. Why there is so much trouble casting a 3 from a character to an integer I will never understand. It's in my data set as an integer, why are you reading it as a character, R?\n\n# There Has To Be A Better Way\nEnter, the ([statsmodels](https://www.statsmodels.org/stable/index.html)) Python library. From the statsmodels website, this library \"supports specifying models using R-style formulas\". My understanding is that this should create a best of both worlds situations in that we can leverage the speed and third-party libraries of Python while also maintaining the simple statistical model creation found in R.\n\n# About statsmodels\nThe statsmodels package was originally written as the models module of the scipy.stats package. When the module was removed in the late 2000s, developer Jonathan Taylor improved the package and decided to release it on its own.\n\nstatsmodels has a host of statistical modeling capabilites available through the statsmodels.api, statsmodels.tsa.api, and statsmodels.formula.api, models. A full list is available ([here](https://www.statsmodels.org/stable/api.html)) with documentation to go along with each.\n\n# An Example\nTo try this pacage out, I want to use this library to see how much returning production influences a college football team's winning. With the rise of the transfer portal in college football, there is a new debate over whether a team should seek out the best talent in the portal, or recruit players out of high school and develop them in their system. A team's percentage of returning EPA (called PPA in our data API) will serve as our independent variable, and the team's winning percentage will be the dependent variable.\n\nEPA stands for Expected Points Added, and measures how many expected points are added or lost on a given play. For example, if a team has the ball on their own 20 yard line, they might be expected to get 2.5 point on that drive. But if they throw a 75 yard pass to take the ball down to the opponents 5 yard line, their expected points for the drive might rise to 6.5. The EPA for that play would be 4. I don't know the exact breakdown of expected points on every yard line, but I this example should demonstrate how EPA works. \n\nI'll be pulling the data from the folks at ([CollegeFootballData](collegefootballdata.com)). I highly recommend this site for using college football data. If you wish to use this library, however, you will need to ([sign up for a free API key](https://collegefootballdata.com/key)) and configure it according to their instructions.\n\nAs you can see, we have a data frame created now with our EPA data. A note on the API response: the response is given as a list of objects, rather than as a dictionary, which is why we need to parse things out before creating a full dataframe.\n\nThe next thing we'll need to do is get the winning percentages for each of these teams and combine that with our EPA data.\n\nAgain we have to do a little extra cleaning when getting our data set up. A team's win/loss data come in as an object (you can see an example in the conferece_games, home_games, and away_games columns, I just left those alone because I don't need that granular information) so we have to do a little work to get the information from that object into its own columns, and then calculate winning percentage. \n\nNow that we have our data set up as needed, let's get to work with modeling. I'd like to do a comparison between the more traditional way of doing linear regression, out of the sklearn.linear_model.LinearRegression class, and doing it this new way with the stats model library. First off, this is how I would set up the data for sklearn.\n\nNow, this is a fairly basic example so there is not a ton that we need with our data before feeding it into our model. Of course, as we create more complex models this would become a more complex task. I am also able to pull out the summary information from the model, but it requires importing other classes and we have to write out formatted strings so we know what we are looking at. \n\nLet's compare this now to the statsmodels library. \n\n# Thoughts on statsmodels\nNow that we have our two models made, I have a couple of initial thoughts before dissecting the output of the models.\n\nThe first is that statsmodels on its own really doesn't incorporate R syntax as much as I initially thought that it would. In fact, it seems that the entire premise of using R syntax for creating models is more related to the ([patsy dependency](https://github.com/pydata/patsy)), which is no longer in development, than the statsmodels library itself.\n\nThat being said, I do find this far easier than sklearn. With statsmodels, I don't need to worry about converting my data into numpy arrays before putting the data into the model. The thing that I find most useful, however, is the fact that there is a built in summary method. Rather than having to pull each summary value out individually and getting it into a formatted string so I know what I am looking at, I can just do `model.summary()` and I can get a full look at what the model produces. \n\nI find this to be far more convenient, and I certainly think I would use statsmodels if given a choice between that and sklearn.\n\n# Evaluating our model\nOur model suggests that returning production plays a very small role, but important role in predicting team success. Our R-Squared value says that only 5% of the variance in a team's winning percentage is explained by returning production, but that there is a statistically significant relationship between the two. So the relationship is there, but the affect on a team's success is pretty weak. I don't think that I would use returning production as a real predictor of team success given what I see in this model. The relationship may be statistically significant, but it does not appear as though it is practically significant. \n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"statsmodel-library.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.40","theme":["cosmo","brand"],"title-block-banner":true,"title":"The statsmodel Python Library","date":"2025-02-01","description":"Comparing and contrasting the statsmodel library against standard R Language","categories":["Python","R"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}